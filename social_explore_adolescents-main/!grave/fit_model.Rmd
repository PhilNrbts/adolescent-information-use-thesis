---
title: "Modelfitting"
author: "Simon"
date: '2022-08-18'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, rjson, DEoptim, doParallel)
source("C_modelfittingCode/models.R")
```

In this document, we will fit a kalman filter to the "social bandit" task that Andrea and I developped. 
First, lets load some data.

```{r}
explore_data <- read_csv(file = "Data/data_coord.csv")
envs <- fromJSON(file = "A_GeneratedFiles/environments_gem_250_var25max.json")
```

```{r}
modelFit <- function(par, subjD, acquisition, k, horizonLength, rounds) {
  # Extract and process parameters
  if (inherits(acquisition, "epsilonGreedy")) {
    epsilon <- 1 / (1 + exp(-(par[length(par)]))) # transform back from unbounded space; epsilon is the last parameter for epsilon greedy
  }
  par <- exp(par) # exponentiate parameters to make a non-negative and convex optimization surface
  # last parameter for all other models is always inverse temperature for softmax
  tau <- par[length(par)]
  # Which posterior function to use; therefore, which parameters to use
  if (inherits(k, "KalmanFilter")) { # null kernel indicates kalman filter model
    kNoise <- par[1]
    parVec <- c(kNoise) # Vector of parameters to send to the KF posterior function
  } else if (inherits(k, "GP")) { # lambda
    lambda <- par[1]
    parVec <- c(lambda, lambda, 1, .0001) # Vector of parameters to send to the GP posterior vector, where sF and sN are fixed
  }
  # Additional acquisition function dependent parameters
  if (inherits(acquisition, "UCB") | inherits(acquisition, "exploreCounts") | inherits(acquisition, "epsilonGreedy")) { # check if UCB is used
    beta <- par[length(par) - 1] # If UCB, beta is always 2nd last
    # refactor beta and tau into gamma and beta_star, where gamma = 1/tau and beta_star = beta/tau
  }
  # which rounds to consider?
  trainingSet <- subset(subjD, round %in% rounds)
  # Vector to store negative log likelihods
  nLL <- rep(0, length(rounds))
  for (r in unique(trainingSet$round)) { # Begin looping through each round
    # subset of data for round r
    roundD <- subset(subjD, round == r)
    horizon <- nrow(roundD)
    # Observations of subject choice behavior
    chosen <- roundD$cells
    chosen <- chosen[2:length(chosen)] # trim first observation, since it wasn't a choice but a randomly revealed tile
    y <- roundD$z[0:(horizon - 1)] # trim off the last observation, because it was not used to inform a choice (round already over)
    x1 <- roundD$x[0:(horizon - 1)]
    x2 <- roundD$y[0:(horizon - 1)]
    # create observation matrix
    X <- as.matrix(cbind(x1, x2))
    # make sure X is a matrix
    X <- as.matrix(X)
    Xnew <- as.matrix(Xnew)
    # Utilties of each choice
    utilities <- NULL
    prevPost <- NULL # set the previous posterior computation to NULL for the kalman filter
    pMat <- NULL
    # loop through observations
    for (i in 1:(horizon - 1)) { # skip the last observation, because no choice was made based on that information
      # new observation
      X1 <- matrix(X[1:i, ], ncol = 2)
      y1 <- y[1:i]
      # Which posterior function to use
      if (inherits(k, "KalmanFilter")) { # kalman filter model
        out <- bayesianMeanTracker(x = X1[i, ], y = y[i], prevPost = prevPost, theta = parVec)
        # update prevPost for the next round
        prevPost <- out
      } else if (inherits(k, "GP")) { # GP with length-scale parameterized kernel
        out <- gpr(X.test = Xnew, theta = parVec, X = X1, Y = y1, k = k) # Mu and Sigma predictions for each of the arms; either GP or Kalman filter
      } else if (inherits(k, "Null")) { # null model
        out <- nullModel() # Mu and Sigma predictions for each of the arms; either GP or Kalman filter
      }
      # Slightly different function calls for each acquisition function
      if (inherits(acquisition, "UCB")) { # UCB takes a beta parameter
        utilityVec <- acquisition(out, c(beta))
      } else if (inherits(acquisition, "exploreCounts")) { # count-based exploration
        utilityVec <- exploreCounts(out, roundD$chosen[1:i], c(beta))
      } else if (inherits(acquisition, "epsilonGreedy")) {
        p <- epsilonGreedy(out, beta, epsilon)
        pMat <- rbind(pMat, t(p))
      } else { # any other
        utilityVec <- acquisition(out)
      }
      if (inherits(acquisition, "softmax")) {
        utilityVec <- utilityVec - max(utilityVec) # avoid overflow
        utilities <- rbind(utilities, t(utilityVec)) # build horizon_length x options matrix, where each row holds the utilities of each choice at each decision time in the search horizon
      }
    }
    # print(utilities)
    if (inherits(acquisition, "softmax")) {
      # Softmax rule
      p <- exp(utilities / tau)
      p <- p / rowSums(p)
      # avoid underflow by setting a floor and a ceiling
      p <- (pmax(p, 0.00001))
      p <- (pmin(p, 0.99999))
      pMat <- p
    }
    # Calculate Negative log likelihood
    nLL[which(unique(trainingSet$round) == r)] <- -sum(log(pMat[cbind(c(1:(horizon - 1)), chosen)]))
  }
  # end loop through rounds
  return(sum(nLL)) # Return negative log likelihoods of all observations
}
```



# Define function for fitting

```{r}
cvfun <- function(data, kernelFun, acquisition, leaveoutindex, gems_yes_no) {
  # subselect participant, horizon and rounds not left out

  # andrea changed: only round with gems
  d1 <- data
  # training set
  # get round names
  rounds <- unique(d1$round)
  # browser()
  # rounds <- 1:6
  # rounds <- count(d1$round)[count(d1$round)$freq>=2,]$x #only rounds where at least 2 clicks have been made
  trainingSet <- rounds[!rounds == leaveoutindex] # remove round specified by leaveoutindex
  # test set
  testSet <- leaveoutindex
  nParams <- 1
  if (inherits(acquisition, "UCB") | inherits(acquisition, "exploreCounts") | inherits(acquisition, "epsilonGreedy")) {
    nParams <- nParams + 1 # add beta parameter
  }
  if (inherits(kernelFun, "GP") | inherits(kernelFun, "KalmanFilter")) {
    nParams <- nParams + 1 # add lambda or error variance
  }
  # Set upper and lower bounds based on nParams
  lbound <- rep(-5, nParams)
  ubound <- rep(4, nParams)

  if (nParams >= 2) { # if 2 or more parameters
    # TRAINING SET

    # this here.
    fit <- DEoptim(modelFit, lower = lbound, upper = ubound, subjD = d1, k = kernelFun, rounds = trainingSet, acquisition = acquisition, DEoptim.control(itermax = 100))



    paramEstimates <- fit$optim$bestmem # MODEL DEPENDENT PARAMETER ESTIMATES
    # TEST SET
    predict <- modelFit(par = paramEstimates, subjD = d1, acquisition = acquisition, k = kernelFun, rounds = testSet)
    output <- c(leaveoutindex, predict, fit$optim$bestmem) # leaveoutindex, nLL, parameters....
  } else {
    # TRAINING SET
    fit <- optimize(modelFit, lower = lbound, upper = ubound, subjD = d1, k = kernelFun, rounds = trainingSet, acquisition = acquisition)
    paramEstimates <- fit$minimum # MODEL DEPENDENT PARAMETER ESTIMATES
    # TEST SET
    predict <- modelFit(par = paramEstimates, subjD = d1, acquisition = acquisition, k = kernelFun, rounds = testSet)
    output <- c(leaveoutindex, predict, fit$minimum) # leaveoutindex, nLL, parameters....
  }
  return(output) # return optimized value
}
```

# Fit
```{r}
# dummy environment
# rescore rewards
explore_data <- explore_data %>% mutate(z = (points - mean(points)) / sd(points))

# parallelize over players
doParallel::registerDoParallel()
n.cores <- parallel::detectCores() - 1
# create the cluster
my.cluster <- parallel::makeCluster(
  n.cores,
  type = "PSOCK"
)
doParallel::registerDoParallel(cl = my.cluster)
```

# fit that thing in parallel
```{r}
foreach(
  x = unique(explore_data$player),
  .packages = c("DEoptim", "dplyr")
) %dopar% {
  Xnew <- as.matrix(expand.grid(0:7, 0:7)) # do this outside the loop for better speed
  output <- c()
  # preallocate round selection because we subset by gems and we cant simply count from 1 to n anymore...
  d1 <- subset(explore_data, player == x & gempresent == 0)
  rounds <- unique(d1$round)
  for (r in rounds) { # loop through rounds in roundList
    cv <- cvfun(data = d1, kernelFun = bayesianMeanTracker, acquisition = ucb, leaveoutindex = r, gems_yes_no = 0) # only try one sub
    output <- rbind(output, cv)
  }
  saveRDS(output, file = paste0("A_GeneratedFiles/modelfits/fit_", x))
}

# readRDS(paste0("A_GeneratedFiles/modelfits/fit_",1))
```

